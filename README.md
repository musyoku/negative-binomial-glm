## 負の二項分布の一般化線形モデルによる最大単語長の予測

Negative Binomial Generalized Linear Modelによる最大単語長の予測の実験コードです。

半教師あり形態素解析でラティスの圧縮に用います。

文字列のある文字に注目すると、この文字はある単語の一部になっていますが、その単語の最大長を予測し可能な単語分割の候補を絞ることで単語分割のサンプリングを高速化することができるそうです。

## 使用

### 動作に必要なもの

- C++ コンパイラ
	- GCC と Apple LLVM で動作を確認しています

- Boost
	- 不完全ベータ関数で使います

### ビルドと実行

```
make train
make test
```

```
./train
./test
```

### パラメータ

- coverage
	- tから何文字を対象に素性ベクトルを作るか
	- contとchに影響する

- c_max
	- 素性にする文字をtから何文字にするか

- t_max
	- tから何文字までの文字種を素性にするか

- sigma
	- MCMCのランダムウォーク時のノイズの標準偏差

重みの事前分布は平均0、分散1の正規分布で固定です。

## 結果

ネットで収集したテキスト78万行のうち10万行を学習、68万行をテストに用いました。

以下は全てテストデータでの結果です。

### 真の単語長ごとの予測精度

```
L	Precision 
1:	1
2:	0.99995
3:	0.999783
4:	0.999053
5:	0.963827
6:	0.946819
7:	0.936784
8:	0.882897
9:	0.847852
10:	0.785453
11:	0.724733
12:	0.659692
13:	0.471319
14:	0.271533
15:	0.129666
16:	0.0783784
n ≥ 5:	0.931269
all:	0.997263
```

L: 真の単語長

### 予測単語長の頻度

```
L	Frequency
1:	506
2:	3742
3:	224735
4:	1707668
5:	1499635
6:	1609497
7:	817332
8:	303112
9:	201034
10:	108836
11:	49285
12:	30805
13:	16063
14:	12064
15:	8111
16:	7865
```

L: 予測単語長

### 真の単語長の分布

```
L	Frequency
1:	4027
2:	30147
3:	32146
4:	30116
5:	17915
6:	12450
7:	8830
8:	6471
9:	4008
10:	2691
11:	1712
12:	1142
13:	739
14:	487
15:	367
16:	297
```

L: 真の単語長

### 予測と真の単語長との誤差

```
L	Mean		StdDev
1:	3.45899:	0.93859
2:	4.02131:	0.97246
3:	3.89740:	1.55167
4:	3.70470:	1.94257
5:	3.51906:	2.31050
6:	3.49838:	2.25847
7:	3.38020:	2.15662
8:	4.45279:	3.06238
9:	3.07420:	3.10812
10:	1.84395:	3.25624
11:	0.65333:	3.21295
12:	-0.25441:	3.31484
13:	-1.86616:	3.47475
14:	-3.11971:	3.70838
15:	-4.42240:	3.63464
16:	-5.51622:	3.74469
```

L: 真の単語長

## 参考文献

- [Inducing Word and Part-of-Speech with Pitman-Yor Hidden Semi-Markov Models](http://chasen.org/~daiti-m/paper/acl2015pyhsmm.pdf)