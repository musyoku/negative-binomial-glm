## 負の二項分布の一般化線形モデルによる最大単語長の予測

Negative Binomial Generalized Linear Modelによる最大単語長の予測の実験コードです。

半教師あり形態素解析でラティスの圧縮に用います。

文字列のある文字に注目すると、この文字はある単語の一部になっていますが、その単語の最大長を予測し可能な単語分割の候補を絞ることで単語分割のサンプリングを高速化することができるそうです。

## 使用

### 動作に必要なもの

- C++ コンパイラ
	- GCC と Apple LLVM で動作を確認しています

- Boost
	- 不完全ベータ関数で使います

### ビルドと実行

```
make train
make test
```

```
./train
./test
```

### パラメータ

- coverage
	- tから何文字を対象に素性ベクトルを作るか
	- contとchに影響する

- c_max
	- 素性にする文字をtから何文字にするか

- t_max
	- tから何文字までの文字種を素性にするか

- sigma
	- MCMCのランダムウォーク時のノイズの標準偏差

重みの事前分布は平均0、分散1の正規分布で固定です。

## 結果

ネットで収集したテキスト78万行のうち10万行を学習、68万行をテストに用いました。

以下は全てテストデータでの結果です。

### 真の単語長ごとの予測精度

```
L	Precision 
1:	1
2:	0.999954
3:	0.999857
4:	0.99897
5:	0.961576
6:	0.946228
7:	0.934631
8:	0.883414
9:	0.852558
10:	0.785261
11:	0.761987
12:	0.674009
13:	0.513384
14:	0.287591
15:	0.137525
16:	0.113514
n ≥ 5:	0.930774
all:	0.99725
```

L: 真の単語長

### 予測単語長の頻度

```
L	Frequency
1:	443
2:	4068
3:	225082
4:	1715916
5:	1478379
6:	1614469
7:	811632
8:	295494
9:	210980
10:	111202
11:	56718
12:	25732
13:	20520
14:	15031
15:	6551
16:	8073
```

L: 予測単語長

### 真の単語長の分布

```
L	Frequency
1:	4027
2:	30147
3:	32146
4:	30116
5:	17915
6:	12450
7:	8830
8:	6471
9:	4008
10:	2691
11:	1712
12:	1142
13:	739
14:	487
15:	367
16:	297
```

L: 真の単語長

### 予測と真の単語長との誤差

```
L	Mean		StdDev
1:	3.46231:	0.95046
2:	4.03007:	0.98899
3:	3.92646:	1.60666
4:	3.73502:	1.96785
5:	3.56011:	2.31201
6:	3.47405:	2.18209
7:	3.56330:	2.43660
8:	4.36280:	2.96231
9:	3.05478:	3.03227
10:	1.93939:	3.23268
11:	0.76613:	3.15384
12:	-0.12115:	3.26267
13:	-1.73996:	3.43601
14:	-2.83504:	3.74290
15:	-4.14735:	3.66847
16:	-5.28919:	3.85482
```

L: 真の単語長

## 参考文献

- [Inducing Word and Part-of-Speech with Pitman-Yor Hidden Semi-Markov Models](http://chasen.org/~daiti-m/paper/acl2015pyhsmm.pdf)